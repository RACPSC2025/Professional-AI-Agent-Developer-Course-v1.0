import os
import time

# Simulaci√≥n de una llamada a un LLM (para no requerir API Key real en este ejemplo b√°sico)
# En un caso real, usar√≠amos openai.ChatCompletion.create() o similar.

def mock_llm_call(prompt, system_message=""):
    """
    Simula la respuesta de un LLM basada en la calidad del prompt.
    """
    full_input = f"System: {system_message}\nUser: {prompt}"
    
    print(f"\n{'='*50}")
    print(f"üì• ENVIANDO PROMPT AL MODELO...")
    print(f"{'='*50}")
    print(f"System: {system_message}")
    print(f"User: {prompt}")
    print(f"{'-'*50}")
    
    # Respuestas simuladas para demostrar la diferencia
    if "R-A-C-E" in system_message or "tabla" in prompt.lower():
        return """
‚úÖ RESPUESTA (Estructurada y Profesional):

| Vulnerabilidad | Severidad | Soluci√≥n Sugerida |
| :--- | :--- | :--- |
| Puerto 22 abierto a 0.0.0.0/0 | CR√çTICA | Restringir acceso SSH solo a la VPN corporativa o IPs espec√≠ficas. |
| Falta de cifrado en tr√°nsito (HTTP) | ALTA | Habilitar TLS/SSL y redirigir todo el tr√°fico a HTTPS. |
| Permisos de S3 bucket p√∫blicos | ALTA | Bloquear acceso p√∫blico y usar pol√≠ticas de bucket restrictivas. |
        """
    elif "R-I-S-E" in system_message:
        return """
‚úÖ RESPUESTA (Chain-of-Thought):

1. **Identificaci√≥n de Hechos**: El usuario pregunta sobre la legalidad de usar datos de scraping para entrenar IA.
2. **B√∫squeda de Precedentes**: Analizando casos recientes como NYT vs OpenAI (2023).
3. **An√°lisis**: Existe una zona gris legal. El "Fair Use" es el argumento principal de defensa, pero no est√° garantizado.
4. **Conclusi√≥n**: Se recomienda precauci√≥n y uso de datasets con licencia expl√≠cita.

**MEMOR√ÅNDUM LEGAL**
Para: Cliente
De: Asistente Legal AI
Asunto: Riesgos de Copyright en Entrenamiento de IA
...
        """
    else:
        return """
‚ùå RESPUESTA (Gen√©rica y Pobre):
Hola. Pues mira, deber√≠as revisar que no tengas puertos abiertos y esas cosas. El cifrado es importante tambi√©n. Ten cuidado con los buckets de S3. Saludos.
        """

def main():
    print("üß™ LABORATORIO DE PROMPT ENGINEERING: Frameworks en Acci√≥n\n")

    # CASO 1: Prompt B√°sico (Sin Framework)
    print("\nüî¥ CASO 1: Prompt B√°sico (Sin Estructura)")
    basic_system = "Eres un asistente √∫til."
    basic_prompt = "Dime qu√© est√° mal en este archivo de configuraci√≥n de seguridad."
    response_basic = mock_llm_call(basic_prompt, basic_system)
    print(response_basic)
    time.sleep(1)

    # CASO 2: Framework R-A-C-E
    print("\nüü¢ CASO 2: Framework R-A-C-E (Role, Action, Context, Expectation)")
    race_system = """
    (R-A-C-E Framework Applied)
    ROLE: Eres un Ingeniero de Ciberseguridad Senior especializado en Cloud Infrastructure.
    CONTEXT: Est√°s auditando una infraestructura cr√≠tica para un banco.
    """
    race_prompt = """
    ACTION: Analiza las vulnerabilidades comunes en configuraciones de nube.
    EXPECTATION: Genera una tabla Markdown con las 3 vulnerabilidades m√°s comunes, su severidad y soluci√≥n t√©cnica.
    """
    response_race = mock_llm_call(race_prompt, race_system)
    print(response_race)
    time.sleep(1)

    # CASO 3: Framework R-I-S-E
    print("\nüîµ CASO 3: Framework R-I-S-E (Role, Input, Steps, Expectation)")
    rise_system = """
    (R-I-S-E Framework Applied)
    ROLE: Eres un Asistente Legal experto en Propiedad Intelectual y Tecnolog√≠a.
    """
    rise_prompt = """
    INPUT: Pregunta sobre scraping para IA.
    STEPS: 1. Identifica hechos. 2. Busca precedentes. 3. Analiza. 4. Concluye.
    EXPECTATION: Un resumen estructurado paso a paso y un memor√°ndum formal.
    """
    response_rise = mock_llm_call(rise_prompt, rise_system)
    print(response_rise)

if __name__ == "__main__":
    main()
