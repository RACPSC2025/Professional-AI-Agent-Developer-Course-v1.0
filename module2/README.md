# üõ†Ô∏è M√≥dulo 2: El Panorama de Frameworks para Agentes de IA

![Module 2 Banner](../images/module2_banner.png)

![Level](https://img.shields.io/badge/Nivel-Intermedio-C3B1E1?style=for-the-badge&logo=python&logoColor=white)
![Time](https://img.shields.io/badge/Tiempo-6_Horas-A7C7E7?style=for-the-badge&labelColor=2D2D44)
![Stack](https://img.shields.io/badge/Stack-9_Frameworks-C3B1E1?style=for-the-badge)

> *"No te cases con una herramienta. Un Ingeniero de IA profesional elige el framework adecuado para el problema adecuado."*

---

## üéØ Visi√≥n General

En el M√≥dulo 1 construimos agentes desde cero. En este m√≥dulo, exploraremos el **ecosistema de frameworks** que simplifican y potencian el desarrollo de agentes de IA. Cubriremos 9 frameworks principales con comparativas detalladas, casos de uso y ejemplos de c√≥digo.

```mermaid
graph TD
    A[Proyecto de Agentes IA] --> B{Caso de Uso}
    B -->|RAG/Retrieval| C[LangChain<br/>LlamaIndex]
    B -->|Multi-Agente| D[CrewAI<br/>AutoGen]
    B -->|Agente Aut√≥nomo| E[LangGraph]
    B -->|Enterprise| F[Semantic Kernel<br/>Google ADK]
    B -->|Prototipo R√°pido| G[Smolagents<br/>Pydantic AI]
    
    style C fill:#4A90E2,stroke:#2E5C8A,stroke-width:2px,color:#fff
    style D fill:#9B59B6,stroke:#6C3483,stroke-width:2px,color:#fff
    style E fill:#E74C3C,stroke:#C0392B,stroke-width:2px,color:#fff
    style F fill:#27AE60,stroke:#1E8449,stroke-width:2px,color:#fff
    style G fill:#F39C12,stroke:#D68910,stroke-width:2px,color:#fff
```

---

## üìö Tabla Comparativa de Alto Nivel

| Framework | Complejidad | Flexibilidad | Comunidad | Mejor Para | GitHub Stars |
|-----------|-------------|--------------|-----------|------------|--------------|
| **[LangChain](#1-langchain)** | Alta | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | RAG, Pipelines complejos | 106k+ |
| **[LangGraph](#2-langgraph)** | Alta | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | Agentes aut√≥nomos, State machines | Parte de LangChain |
| **[CrewAI](#3-crewai)** | Media | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | Multi-agente, Roles claros | 25k+ |
| **[AutoGen](#4-autogen)** | Media | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | Conversaciones, Code execution | 43k+ |
| **[Semantic Kernel](#5-semantic-kernel)** | Media | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | Enterprise, Microsoft stack | 22k+ |
| **[Smolagents](#6-smolagents)** | Baja | ‚≠ê‚≠ê | ‚≠ê‚≠ê | Prototipos, Simplicidad | Parte de HuggingFace |
| **[LlamaIndex](#7-llamaindex)** | Media | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | RAG, Document Q&A | 38k+ |
| **[Pydantic AI](#8-pydantic-ai)** | Baja | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | Type safety, Structured outputs | Nuevo (2024) |
| **[Google ADK](#9-google-adk-agent-development-kit)** | Media | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | Google Cloud, Multi-agent, Enterprise | Nuevo (2024) |

---

## 1. LangChain

### üéØ Filosof√≠a
**"Swiss Army Knife"** - Toolkit modular y flexible para aplicaciones LLM

### üìñ Descripci√≥n
LangChain es el framework m√°s maduro y establecido para construir aplicaciones con LLMs. Ofrece un ecosistema completo con componentes modulares, integraciones masivas (100+) y herramientas de producci√≥n.

### ‚úÖ Ventajas
- **Ecosistema completo**: LangChain, LangGraph, LangSmith, LangServe
- **Integraciones masivas**: M√°s de 100 integraciones con modelos, vectorstores, APIs
- **Documentaci√≥n extensa**: Miles de ejemplos y tutoriales
- **Comunidad activa**: 106k+ estrellas en GitHub
- **Production-ready**: Herramientas para deployment, monitoring, evaluaci√≥n

### ‚ùå Desventajas
- **Curva de aprendizaje empinada**: Muchos conceptos y abstracciones
- **Boilerplate**: M√°s c√≥digo para casos simples
- **API cambiante**: Actualizaciones frecuentes pueden romper c√≥digo
- **Overkill para proyectos simples**: Puede ser demasiado para casos b√°sicos

### üíª Ejemplo de C√≥digo

```python
"""
Ejemplo: Pipeline RAG b√°sico con LangChain
Framework: LangChain 0.1+
Objetivo: Sistema de Q&A sobre documentos
"""

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

# 1. Setup componentes
llm = ChatOpenAI(model="gpt-4o-mini")
embeddings = OpenAIEmbeddings()

# 2. Crear vectorstore
documents = ["LangChain simplifica el desarrollo de aplicaciones LLM"]
vectorstore = Chroma.from_texts(documents, embeddings)
retriever = vectorstore.as_retriever()

# 3. Crear prompt template
template = """Responde la pregunta bas√°ndote en el contexto:

Contexto: {context}

Pregunta: {question}

Respuesta:"""

prompt = ChatPromptTemplate.from_template(template)

# 4. LCEL Chain (LangChain Expression Language)
chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# 5. Ejecutar
result = chain.invoke("¬øQu√© es LangChain?")
print(result)
```

### üéØ Casos de Uso Ideales
- **RAG systems complejos** con m√∫ltiples fuentes de datos
- **Pipelines de procesamiento** de documentos
- **Aplicaciones que necesitan muchas integraciones**
- **Proyectos que requieren observabilidad** (LangSmith)

### üìö Referencias
- **Documentaci√≥n oficial**: https://python.langchain.com/docs/
- **GitHub**: https://github.com/langchain-ai/langchain
- **Actualizaciones 2024**: Nuevo `create_agent`, middlewares prebuilt, LangGraph Cloud

---

## 2. LangGraph

### üéØ Filosof√≠a
**"State Machines for LLMs"** - Grafos de estado para flujos complejos

### üìñ Descripci√≥n
LangGraph extiende LangChain para crear agentes con flujos de control complejos usando grafos de estado. Ideal para agentes aut√≥nomos que necesitan loops, condicionales y state management robusto.

### ‚úÖ Ventajas
- **Control total sobre flujo**: Loops, condicionales, branches
- **State management robusto**: Checkpointing y persistencia
- **Human-in-the-loop nativo**: Breakpoints y aprobaciones
- **Debugging visual**: Visualizaci√≥n de grafos
- **Streaming**: Soporte para streaming de estado y tokens

### ‚ùå Desventajas
- **M√°s complejo que chains**: Requiere pensar en grafos
- **Curva de aprendizaje**: Conceptos adicionales sobre LangChain
- **Documentaci√≥n en evoluci√≥n**: Menos ejemplos que LangChain base

### üíª Ejemplo de C√≥digo

```python
"""
Ejemplo: Agente con ReAct pattern usando LangGraph
Framework: LangGraph
Objetivo: Agente que razona y act√∫a en loops
"""

from langgraph.graph import StateGraph, END
from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from typing import TypedDict, Annotated
import operator

# 1. Definir herramientas
@tool
def search_web(query: str) -> str:
    """Busca informaci√≥n en la web"""
    return f"Resultados para: {query}"

@tool
def calculate(expression: str) -> float:
    """Calcula expresiones matem√°ticas"""
    return eval(expression)

# 2. Definir estado
class AgentState(TypedDict):
    messages: Annotated[list, operator.add]
    next_action: str

# 3. Crear agente ReAct con LangGraph
llm = ChatOpenAI(model="gpt-4o-mini")
tools = [search_web, calculate]

# Usar agente prebuilt de LangGraph
agent = create_react_agent(llm, tools)

# 4. Ejecutar
inputs = {"messages": [("user", "¬øCu√°l es 25 * 4 y busca informaci√≥n sobre Python?")]}
result = agent.invoke(inputs)

for message in result["messages"]:
    print(f"{message.type}: {message.content}")
```

### üéØ Casos de Uso Ideales
- **Agentes aut√≥nomos** con m√∫ltiples pasos de razonamiento
- **Workflows con decisiones condicionales**
- **Sistemas que necesitan retry logic**
- **Aplicaciones con human-in-the-loop**

### üìö Referencias
- **Documentaci√≥n oficial**: https://langchain-ai.github.io/langgraph/
- **GitHub**: Parte de LangChain
- **Actualizaciones 2024**: LangGraph Cloud (beta), ReAct agent prebuilt, streaming mejorado

---

## 3. CrewAI

### üéØ Filosof√≠a
**"Role-Based Multi-Agent"** - Equipos de agentes especializados

### üìñ Descripci√≥n
CrewAI simplifica la creaci√≥n de sistemas multi-agente donde cada agente tiene un rol, objetivo y backstory espec√≠ficos. Ideal para workflows colaborativos tipo "equipo de trabajo".

### ‚úÖ Ventajas
- **Muy intuitivo**: Abstracci√≥n de alto nivel
- **Menos c√≥digo**: Para casos multi-agente comunes
- **Roles claros**: F√°cil de conceptualizar (Investigador, Escritor, etc.)
- **Procesos flexibles**: Sequential, Hierarchical, Hybrid
- **Memoria compartida**: Los agentes comparten contexto

### ‚ùå Desventajas
- **Menos flexible que LangChain**: Opinado (opinionated)
- **Menos integraciones**: Ecosistema m√°s peque√±o
- **Comunidad m√°s peque√±a**: Menos recursos y ejemplos
- **Limitado para non-multi-agent**: No ideal para agentes individuales

### üíª Ejemplo de C√≥digo

```python
"""
Ejemplo: Equipo de investigaci√≥n y escritura con CrewAI
Framework: CrewAI
Objetivo: Sistema multi-agente colaborativo
"""

from crewai import Agent, Task, Crew, Process

# 1. Definir agentes con roles
investigador = Agent(
    role='Investigador Senior',
    goal='Descubrir informaci√≥n relevante y precisa',
    backstory="""Eres un investigador experto con a√±os de experiencia
    en b√∫squeda y an√°lisis de informaci√≥n. Tu especialidad es encontrar
    fuentes confiables y extraer insights valiosos.""",
    verbose=True,
    allow_delegation=False
)

escritor = Agent(
    role='Escritor T√©cnico',
    goal='Crear contenido claro y enganchante',
    backstory="""Eres un escritor profesional especializado en
    transformar informaci√≥n compleja en contenido accesible y
    atractivo para audiencias diversas.""",
    verbose=True,
    allow_delegation=False
)

# 2. Definir tareas
tarea_investigacion = Task(
    description="""Investiga sobre los frameworks de agentes de IA m√°s
    populares en 2024. Enf√≥cate en LangChain, CrewAI y AutoGen.""",
    agent=investigador,
    expected_output="Reporte detallado con hallazgos clave"
)

tarea_escritura = Task(
    description="""Usando la investigaci√≥n, escribe un art√≠culo de blog
    de 500 palabras comparando los frameworks. Debe ser t√©cnico pero
    accesible.""",
    agent=escritor,
    expected_output="Art√≠culo de blog completo"
)

# 3. Formar el equipo (Crew)
crew = Crew(
    agents=[investigador, escritor],
    tasks=[tarea_investigacion, tarea_escritura],
    process=Process.sequential,  # Tareas en secuencia
    verbose=True
)

# 4. Ejecutar
resultado = crew.kickoff()
print(resultado)
```

### üéØ Casos de Uso Ideales
- **Equipos de agentes colaborativos**
- **Workflows de investigaci√≥n + escritura**
- **Proyectos con roles bien definidos**
- **Automatizaci√≥n de procesos empresariales**

### üìö Referencias
- **Documentaci√≥n oficial**: https://docs.crewai.com/
- **GitHub**: https://github.com/joaomdmoura/crewAI
- **Actualizaciones 2024**: Flows para orquestaci√≥n avanzada, integraci√≥n con LangGraph

---

## 4. AutoGen

### üéØ Filosof√≠a
**"Conversational Agents"** - Agentes que conversan entre s√≠

### üìñ Descripci√≥n
AutoGen (Microsoft) facilita la creaci√≥n de sistemas multi-agente basados en conversaciones. Destaca por su soporte para code execution y el patr√≥n UserProxy.

### ‚úÖ Ventajas
- **Respaldado por Microsoft**: Soporte enterprise
- **Code execution nativo**: Ejecuta c√≥digo Python autom√°ticamente
- **Conversaciones complejas**: Group chat, multi-agente
- **AutoGen Studio**: GUI sin c√≥digo para prototipos
- **Soporte multi-lenguaje**: Python y .NET

### ‚ùå Desventajas
- **Documentaci√≥n menos extensa**: Comparado con LangChain
- **Puede ser verboso**: Configuraci√≥n detallada requerida
- **Menos integraciones**: Ecosistema m√°s limitado

### üíª Ejemplo de C√≥digo

```python
"""
Ejemplo: Agente conversacional con code execution
Framework: AutoGen v0.4
Objetivo: Agente que genera y ejecuta c√≥digo
"""

from autogen import AssistantAgent, UserProxyAgent, config_list_from_json

# 1. Configurar modelos
config_list = [
    {
        "model": "gpt-4o-mini",
        "api_key": "your-api-key"
    }
]

llm_config = {
    "config_list": config_list,
    "temperature": 0
}

# 2. Crear agente asistente
assistant = AssistantAgent(
    name="assistant",
    llm_config=llm_config,
    system_message="""Eres un asistente de programaci√≥n Python.
    Ayudas a escribir c√≥digo limpio y eficiente."""
)

# 3. Crear user proxy (ejecuta c√≥digo)
user_proxy = UserProxyAgent(
    name="user_proxy",
    human_input_mode="NEVER",  # Autom√°tico
    max_consecutive_auto_reply=10,
    code_execution_config={
        "work_dir": "coding",
        "use_docker": False  # Cambiar a True en producci√≥n
    }
)

# 4. Iniciar conversaci√≥n
user_proxy.initiate_chat(
    assistant,
    message="""Escribe una funci√≥n Python que calcule los primeros
    N n√∫meros de Fibonacci y pru√©bala con N=10"""
)
```

### üéØ Casos de Uso Ideales
- **Agentes que necesitan conversar**
- **Code generation y execution**
- **Debugging asistido por IA**
- **Aplicaciones enterprise con Microsoft stack**

### üìö Referencias
- **Documentaci√≥n oficial**: https://microsoft.github.io/autogen/
- **GitHub**: https://github.com/microsoft/autogen
- **Actualizaciones 2024**: AutoGen v0.4 (redise√±o completo), arquitectura as√≠ncrona

---

## 5. Semantic Kernel

### üéØ Filosof√≠a
**"Enterprise-Ready AI"** - Framework de Microsoft para producci√≥n

### üìñ Descripci√≥n
Semantic Kernel es el framework enterprise de Microsoft para integrar capacidades de IA en aplicaciones. Dise√±ado para escalabilidad, seguridad y compatibilidad con el ecosistema Microsoft.

### ‚úÖ Ventajas
- **Respaldo de Microsoft**: Soporte enterprise
- **Multi-lenguaje**: C#, Python, Java
- **Integraciones enterprise**: Azure, Microsoft Graph
- **Patterns bien documentados**: Plugins, Planners, Memory
- **Seguridad**: Built-in security features

### ‚ùå Desventajas
- **M√°s verboso**: Comparado con frameworks Python-first
- **Comunidad Python m√°s peque√±a**: Orientado a .NET
- **Curva de aprendizaje**: Conceptos enterprise

### üíª Ejemplo de C√≥digo

```python
"""
Ejemplo: Plugin b√°sico con Semantic Kernel
Framework: Semantic Kernel (Python)
Objetivo: Crear un plugin reutilizable
"""

import semantic_kernel as sk
from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion

# 1. Crear kernel
kernel = sk.Kernel()

# 2. Agregar servicio de IA
kernel.add_service(
    OpenAIChatCompletion(
        service_id="default",
        ai_model_id="gpt-4o-mini",
        api_key="your-api-key"
    )
)

# 3. Definir plugin como funci√≥n
@kernel.function(
    name="get_weather",
    description="Obtiene el clima de una ciudad"
)
def get_weather(city: str) -> str:
    """Simula obtener el clima"""
    return f"El clima en {city} es soleado, 25¬∞C"

# 4. Registrar plugin
kernel.add_plugin(
    plugin_name="WeatherPlugin",
    functions=[get_weather]
)

# 5. Usar el plugin
result = kernel.invoke(
    function_name="get_weather",
    plugin_name="WeatherPlugin",
    city="Madrid"
)

print(result)
```

### üéØ Casos de Uso Ideales
- **Aplicaciones enterprise**
- **Integraci√≥n con Microsoft ecosystem** (Azure, Office 365)
- **Proyectos multi-lenguaje**
- **Aplicaciones que requieren compliance**

### üìö Referencias
- **Documentaci√≥n oficial**: https://learn.microsoft.com/en-us/semantic-kernel/
- **GitHub**: https://github.com/microsoft/semantic-kernel
- **Actualizaciones 2024**: Documentaci√≥n renovada, nuevos conceptos, Agents page

---

## 6. Smolagents

### üéØ Filosof√≠a
**"Lightweight & Fast"** - Agentes minimalistas de HuggingFace

### üìñ Descripci√≥n
Smolagents es un framework ligero de HuggingFace enfocado en simplicidad y eficiencia. Usa "Code Agents" donde los agentes escriben y ejecutan c√≥digo Python.

### ‚úÖ Ventajas
- **Muy ligero**: ~1000 l√≠neas de c√≥digo core
- **R√°pido de aprender**: API simple
- **Code agents**: Agentes escriben Python directamente
- **Model agnostic**: Funciona con cualquier LLM
- **Integraci√≥n HuggingFace**: Acceso al Hub

### ‚ùå Desventajas
- **Menos features**: Comparado con frameworks completos
- **Comunidad peque√±a**: Menos recursos
- **Documentaci√≥n limitada**: Framework nuevo
- **No ideal para producci√≥n compleja**: Mejor para prototipos

### üíª Ejemplo de C√≥digo

```python
"""
Ejemplo: Code Agent con Smolagents
Framework: Smolagents (HuggingFace)
Objetivo: Agente que escribe y ejecuta c√≥digo
"""

from smolagents import CodeAgent, HfApiModel, DuckDuckGoSearchTool

# 1. Configurar modelo
model = HfApiModel(model_id="Qwen/Qwen2.5-Coder-32B-Instruct")

# 2. Configurar herramientas
tools = [DuckDuckGoSearchTool()]

# 3. Crear agente
agent = CodeAgent(
    tools=tools,
    model=model,
    max_steps=10
)

# 4. Ejecutar tarea
result = agent.run(
    "Busca informaci√≥n sobre los frameworks de agentes de IA m√°s populares"
)

print(result)
```

### üéØ Casos de Uso Ideales
- **Prototipos r√°pidos**
- **Agentes simples**
- **Proyectos con restricciones de recursos**
- **Experimentaci√≥n con code agents**

### üìö Referencias
- **Documentaci√≥n oficial**: https://huggingface.co/docs/smolagents
- **GitHub**: Parte de HuggingFace
- **Caracter√≠sticas**: Code agents, sandboxed execution, model agnostic

---

## 7. LlamaIndex

### üéØ Filosof√≠a
**"Data Framework for LLMs"** - Especializado en RAG y datos

### üìñ Descripci√≥n
LlamaIndex (antes GPT Index) es el framework l√≠der para construir aplicaciones RAG. Ofrece data connectors, indices y query engines optimizados para b√∫squeda sem√°ntica.

### ‚úÖ Ventajas
- **Mejor para RAG**: Dise√±ado espec√≠ficamente para RAG
- **Data connectors**: 100+ conectores (APIs, DBs, PDFs)
- **Optimizado para b√∫squeda**: Indices y retrievers avanzados
- **Documentaci√≥n clara**: Excelentes tutoriales RAG
- **Composable retrievers**: T√©cnicas RAG avanzadas

### ‚ùå Desventajas
- **Menos flexible para non-RAG**: Enfocado en RAG
- **Overlap con LangChain**: Funcionalidad similar
- **Comunidad m√°s peque√±a**: Comparado con LangChain

### üíª Ejemplo de C√≥digo

```python
"""
Ejemplo: RAG system con LlamaIndex
Framework: LlamaIndex
Objetivo: Sistema de Q&A sobre documentos
"""

from llama_index.core import VectorStoreIndex, SimpleDirectoryReader
from llama_index.core import Settings
from llama_index.llms.openai import OpenAI
from llama_index.embeddings.openai import OpenAIEmbedding

# 1. Configurar settings globales
Settings.llm = OpenAI(model="gpt-4o-mini")
Settings.embed_model = OpenAIEmbedding(model="text-embedding-3-small")

# 2. Cargar documentos
documents = SimpleDirectoryReader("./data").load_data()

# 3. Crear √≠ndice
index = VectorStoreIndex.from_documents(documents)

# 4. Crear query engine
query_engine = index.as_query_engine(
    similarity_top_k=3,
    response_mode="compact"
)

# 5. Hacer queries
response = query_engine.query("¬øQu√© frameworks de IA existen?")
print(response)

# Ver fuentes
for node in response.source_nodes:
    print(f"Score: {node.score:.2f}")
    print(f"Text: {node.text[:100]}...")
```

### üéØ Casos de Uso Ideales
- **RAG systems**
- **Document Q&A**
- **Knowledge bases**
- **Semantic search applications**

### üìö Referencias
- **Documentaci√≥n oficial**: https://docs.llamaindex.ai/
- **GitHub**: https://github.com/run-llama/llama_index
- **Actualizaciones 2024**: RankGPT, Composable Retrievers, mejoras en RAG

---

## 8. Pydantic AI

### üéØ Filosof√≠a
**"Type-Safe Agents"** - Agentes con validaci√≥n de tipos

### üìñ Descripci√≥n
Pydantic AI (2024) es un framework nuevo del equipo de Pydantic enfocado en type safety y structured outputs. Usa Pydantic models para validaci√≥n robusta.

### ‚úÖ Ventajas
- **Type safety**: Validaci√≥n est√°tica con mypy/pyright
- **Structured outputs**: Pydantic models garantizan estructura
- **API limpia**: Pythonic y moderna
- **Dependency injection**: Type-safe DI system
- **Menos errores**: Catch errors antes de runtime

### ‚ùå Desventajas
- **Muy nuevo**: Lanzado en 2024
- **Comunidad peque√±a**: Pocos recursos a√∫n
- **Features limitados**: Comparado con frameworks maduros
- **Documentaci√≥n en crecimiento**: A√∫n en desarrollo

### üíª Ejemplo de C√≥digo

```python
"""
Ejemplo: Agente type-safe con Pydantic AI
Framework: Pydantic AI
Objetivo: Structured output con validaci√≥n
"""

from pydantic import BaseModel, Field
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel

# 1. Definir modelo de salida con Pydantic
class FrameworkComparison(BaseModel):
    """Comparaci√≥n estructurada de frameworks"""
    framework_name: str = Field(description="Nombre del framework")
    best_for: str = Field(description="Para qu√© es mejor")
    complexity: int = Field(ge=1, le=5, description="Complejidad 1-5")
    github_stars: int = Field(description="Estrellas en GitHub")

# 2. Crear agente con output type
model = OpenAIModel("gpt-4o-mini")

agent = Agent(
    model=model,
    result_type=FrameworkComparison,
    system_prompt="""Eres un experto en frameworks de agentes de IA.
    Proporciona comparaciones precisas y estructuradas."""
)

# 3. Ejecutar con type safety
result = agent.run_sync("Compara LangChain")

# 4. Result es type-safe (FrameworkComparison)
print(f"Framework: {result.data.framework_name}")
print(f"Mejor para: {result.data.best_for}")
print(f"Complejidad: {result.data.complexity}/5")
print(f"Stars: {result.data.github_stars:,}")

# mypy/pyright validar√°n los tipos!
```

### üéØ Casos de Uso Ideales
- **Aplicaciones que requieren type safety**
- **Structured data extraction**
- **Proyectos con validaci√≥n estricta**
- **Teams que usan mypy/pyright**

### üìö Referencias
- **Documentaci√≥n oficial**: https://ai.pydantic.dev/
- **GitHub**: https://github.com/pydantic/pydantic-ai
- **Lanzamiento**: 2024 (muy nuevo)

---

## 9. Google ADK (Agent Development Kit)

### üéØ Filosof√≠a
**"Cloud-Native Agent Platform"** - Framework de Google para sistemas multi-agente en producci√≥n

### üìñ Descripci√≥n
Google Agent Development Kit (ADK) es el framework oficial de Google para construir, desplegar y escalar sistemas de agentes de IA. Dise√±ado para integraci√≥n nativa con Google Cloud (Vertex AI Agent Engine) y los modelos Gemini. Lanzado en 2024, ofrece un balance √∫nico entre simplicidad y poder enterprise.

### ‚úÖ Ventajas
- **Native Google Cloud**: Deployment directo a Vertex AI Agent Engine
- **Multi-language**: Python, Go, Java (3 SDKs oficiales)
- **Workflow agents**: Sequential, Parallel, Loop, LlmAgent (tipos pre-built)
- **Built-in evaluation**: Testing de respuesta y trayectoria integrado
- **Safety patterns**: Security y safety best practices desde el inicio
- **Agent composition**: Agentes como herramientas de otros agentes
- **MCP support**: Model Context Protocol para interoperabilidad
- **Type-safe**: Pydantic validation nativa
- **Google tools ecosystem**: BigQuery, Code Execution, Google Search integrados

### ‚ùå Desventajas
- **Muy nuevo**: Lanzado en 2024 (framework joven)
- **Comunidad peque√±a**: Pocos recursos comparado con LangChain
- **Documentaci√≥n en crecimiento**: Menos ejemplos que frameworks maduros
- **Google Cloud oriented**: Optimizado para GCP (aunque funciona standalone)
- **Menos integraciones**: Ecosistema m√°s peque√±o que Lang Chain (por ahora)

### üíª Ejemplo de C√≥digo

```python
"""
Ejemplo: Sistema multi-agente con Google ADK
Framework: Google ADK
Objetivo: Research pipeline con workflow agents
"""

from google.adk.agents import LlmAgent
from google.adk.workflow_agents import SequentialAgent
from google.adk.tools import tool

# 1. Definir herramientas personalizadas
@tool
def search_documents(query: str) -> str:
    """Search internal documentation"""
    # Simulado - en producci√≥n usar vector DB
    return f"Found documentation for: {query}"

@tool
def analyze_code(code_snippet: str) -> str:
    """Analyze code quality"""
    return f"Code analysis: {len(code_snippet)} chars, looks good"

# 2. Crear agentes especializados
researcher = LlmAgent(
    model="gemini-2.0-flash-exp",
    name="researcher",
    description="Researches topics using documentation",
    instruction="""You are a research specialist. Use the search_documents
    tool to find relevant information. Be thorough and accurate.""",
    tools=[search_documents]
)

analyst = LlmAgent(
    model="gemini-2.0-flash-exp",
    name="analyst",
    description="Analyzes code quality",
    instruction="""You are a code analyst. Review code and provide
    actionable feedback using the analyze_code tool.""",
    tools=[analyze_code]
)

writer = LlmAgent(
    model="gemini-2.0-flash-exp",
    name="writer",
    description="Writes professional summaries",
    instruction="You write clear, concise summaries of research findings."
)

# 3. Crear workflow secuencial
research_pipeline = SequentialAgent(
    name="research_workflow",
    description="Complete research pipeline",
    agents=[researcher, analyst, writer]  # Ejecutan en orden
)

# 4. Ejecutar el workflow
task = "Research best practices for Python async programming and analyze example code"
result = research_pipeline.run(task)

print(f"Pipeline Result:\n{result.output_text}")

# 5. (OPCIONAL) Deployment a Vertex AI Agent Engine
# from google.adk.deploy import deploy_to_vertex_ai
# 
# deploy_to_vertex_ai(
#     agent=research_pipeline,
#     project_id="your-gcp-project",
#     region="us-central1"
# )
```

### üèóÔ∏è Arquitectura de Google ADK

```mermaid
graph TB
    A[App] --> B[Root Agent]
    B --> C[Workflow Agents]
    B --> D[LLM Agents]
    
    C --> E[Sequential<br/>Agent]
    C --> F[Parallel<br/>Agent]
    C --> G[Loop<br/>Agent]
    
    D --> H[Custom<br/>Agents]
    
    E --> I[Tools]
    F --> I
    G --> I
    H --> I
    
    I --> J[Built-in Tools]
    I --> K[Custom Tools]
    I --> L[Google Cloud<br/>Tools]
    
    J --> M[Search]
    J --> N[Code Exec]
    
    L --> O[BigQuery]
    L --> P[Cloud SQL]
    
    style B fill:#4285f4,color:#fff,stroke:#1a73e8,stroke-width:2px
    style C fill:#ea4335,color:#fff,stroke:#c5221f,stroke-width:2px
    style I fill:#fbbc04,color:#333,stroke:#f9ab00,stroke-width:2px
```

### üéØ Casos de Uso Ideales
- **Google Cloud ecosystem**: Proyectos en GCP con Vertex AI
- **Enterprise deployment**: Apps que requieren escalabilidad cloud-native
- **Multi-agent systems**: Jerarqu√≠as y orquestaci√≥n compleja
- **Type-safe workflows**: Proyectos que requieren validation estricta
- **Gemini integration**: Aprovechar modelos Gemini al m√°ximo
- **Evaluation-driven development**: Projecto con testing riguroso

### üÜö Comparaci√≥n R√°pida vs. Otros Frameworks

| Aspecto | Google ADK | LangChain | CrewAI |
|---------|------------|-----------|---------|
| **Deployment** | Vertex AI nativo | LangServe | Custom |
| **Workflow types** | 4 pre-built | Custom chains | Sequential/Hierarchical |
| **Evaluation** | Built-in | LangSmith (paid) | Limited |
| **Type safety** | Pydantic native | Partial | Limited |
| **Learning curve** | Media | Alta | Media |
| **Lines of code** | ~30-40 | ~50-60 | ~40-50 |
| **Best for** | Google Cloud | Flexibility | Multi-agent UX |

### üìö Referencias
- **Documentaci√≥n oficial**: https://google.github.io/adk-docs/
- **GitHub Python**: https://github.com/google/adk-python
- **GitHub Go**: https://github.com/google/adk-go
- **GitHub Java**: https://github.com/google/adk-java
- **Vertex AI Agent Engine**: https://cloud.google.com/vertex-ai/docs/generative-ai/agent-engine
- **Actualizaciones 2024**: Multi-language support, MCP protocol, built-in evaluation, reflection patterns

### üí° Cu√°ndo Elegir Google ADK

‚úÖ **√öSALO SI:**
- Est√°s en Google Cloud Platform
- Necesitas deployment escalable sin configuraci√≥n compleja
- Quieres type-safety con Pydantic
- Requieres evaluation integrada
- Prefieres c√≥digo m√°s limpio y menos boilerplate

‚ùå **NO LO USES SI:**
- Necesitas 100+ integraciones (usa LangChain)
- El framework debe ser super maduro (esperat√≠tulo a 2025)
- No est√°s en Google Cloud Y no quieres aprender uno nuevo
- Necesitas m√°xima flexibilidad (LangChain es m√°s flexible)

---

## üéØ Matriz de Decisi√≥n

### ¬øCu√°ndo usar cada framework?

```mermaid
graph TD
    A[¬øQu√© necesitas construir?] --> B{Tipo de aplicaci√≥n}
    
    B -->|RAG/Documentos| C{Complejidad}
    C -->|Simple| D[LlamaIndex]
    C -->|Complejo| E[LangChain]
    
    B -->|Multi-Agente| F{Estilo}
    F -->|Roles claros| G[CrewAI]
    F -->|Conversacional| H[AutoGen]
    
    B -->|Agente Aut√≥nomo| I[LangGraph]
    
    B -->|Enterprise| J{Stack}
    J -->|Microsoft| K[Semantic Kernel]
    J -->|General| L[LangChain + LangSmith]
    
    B -->|Prototipo| M{Prioridad}
    M -->|Velocidad| N[Smolagents]
    M -->|Type Safety| O[Pydantic AI]
```

### Tabla de Decisi√≥n Detallada

| Si necesitas... | Usa... | Por qu√©... |
|-----------------|--------|------------|
| **RAG sobre documentos** | LlamaIndex o LangChain | Optimizados para retrieval sem√°ntico |
| **Equipo de agentes colaborando** | CrewAI | Abstracci√≥n role-based intuitiva |
| **Agentes conversando** | AutoGen | Soporte nativo para multi-agent chat |
| **Flujos complejos con loops** | LangGraph | State machines y control de flujo |
| **Integraci√≥n Microsoft** | Semantic Kernel | Dise√±ado para Azure y .NET |
| **Integraci√≥n Google Cloud** | Google ADK | Vertex AI Agent Engine nativo |
| **Prototipo r√°pido** | Smolagents | M√≠nimo boilerplate |
| **Type safety estricto** | Pydantic AI | Validaci√≥n de tipos en compile-time |
| **M√°xima flexibilidad** | LangChain | M√°s componentes y opciones |

---

## üíª Proyectos Pr√°cticos

### üü¢ Nivel B√°sico: "Hello World" en 4 Frameworks
**Archivo:** `examples/basic/01_framework_comparison.py`

Implementar la misma funcionalidad (generador de texto estructurado) en LangChain, CrewAI, AutoGen y Pydantic AI para comparar sintaxis.

### üü° Nivel Intermedio: Benchmark de Performance
**Archivo:** `examples/intermediate/02_framework_benchmark.py`

Medir latencia, costo y complejidad de c√≥digo para una tarea est√°ndar (RAG Q&A) en m√∫ltiples frameworks.

### üî¥ Nivel Avanzado: Meta-Router Inteligente
**Archivo:** `examples/advanced/03_smart_framework_router.py`

Sistema que analiza la query del usuario y autom√°ticamente selecciona el framework m√°s apropiado para ejecutarla.

---

## üìä Comparaci√≥n de Caracter√≠sticas

| Caracter√≠stica | LangChain | LangGraph | CrewAI | AutoGen | Semantic Kernel | Smolagents | LlamaIndex | Pydantic AI | Google ADK |
|----------------|-----------|-----------|--------|---------|-----------------|------------|------------|-------------|------------|
| **RAG** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Multi-Agent** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **State Management** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Code Execution** | ‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Type Safety** | ‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Documentaci√≥n** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| **Comunidad** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê |
| **Curva Aprendizaje** | Alta | Alta | Media | Media | Media | Baja | Media | Baja | Media |

---

## üéì Mejores Pr√°cticas

### 1. **No uses un framework para todo**
- Combina frameworks seg√∫n necesidades
- Ejemplo: LangChain para RAG + CrewAI para multi-agente

### 2. **Empieza simple**
- Prototipar con Smolagents o Pydantic AI
- Migrar a LangChain/LangGraph cuando necesites m√°s features

### 3. **Considera el ecosistema**
- LangChain tiene LangSmith (observabilidad)
- AutoGen tiene AutoGen Studio (GUI)
- Semantic Kernel tiene integraci√≥n Azure

### 4. **Eval√∫a el costo de mantenimiento**
- Frameworks nuevos cambian r√°pido
- LangChain tiene breaking changes frecuentes
- Semantic Kernel es m√°s estable (enterprise)

### 5. **Mide antes de optimizar**
- Usa benchmarks para decisiones
- No asumas que un framework es "m√°s r√°pido"

---

## üìö Recursos Adicionales

### Art√≠culos Comparativos
- [Bright Data: 12 Frameworks de Agentes IA 2025](https://brightdata.es/blog/ai/best-ai-agent-frameworks)
- [Analytics Vidhya: Top 7 Frameworks 2025](https://www.analyticsvidhya.com/blog/2024/07/ai-agent-frameworks/)

### Documentaci√≥n Oficial
- **LangChain**: https://python.langchain.com/docs/
- **LangGraph**: https://langchain-ai.github.io/langgraph/
- **CrewAI**: https://docs.crewai.com/
- **AutoGen**: https://microsoft.github.io/autogen/
- **Semantic Kernel**: https://learn.microsoft.com/semantic-kernel/
- **Smolagents**: https://huggingface.co/docs/smolagents
- **LlamaIndex**: https://docs.llamaindex.ai/
- **Pydantic AI**: https://ai.pydantic.dev/
- **Google ADK**: https://google.github.io/adk-docs/

---

## üöÄ Pr√≥ximos Pasos

Una vez que domines la selecci√≥n de frameworks, estar√°s listo para:

1. ‚úÖ Elegir el framework correcto para cada proyecto
2. ‚úÖ Combinar frameworks para soluciones h√≠bridas
3. ‚úÖ Optimizar costos usando el framework apropiado
4. ‚úÖ Construir sistemas de producci√≥n robustos

### Contin√∫a tu Aprendizaje

‚û°Ô∏è **[M√≥dulo 3: Patrones Cognitivos](../module3/README.md)** - Aprende patrones avanzados como ReAct, Reflexion y Chain-of-Thought

---

<div align="center">

**[‚¨ÖÔ∏è M√≥dulo Anterior 1.5](../module1.5/README.md)** | **[üè† Inicio](../README.md)** | **[Siguiente M√≥dulo ‚û°Ô∏è](../module3/README.md)**

</div>

---

## üìù Referencias Bibliogr√°ficas

1. **LangChain Official Documentation** (2024). "LangChain: Building applications with LLMs". https://python.langchain.com/docs/
2. **Microsoft Research** (2024). "AutoGen: Enabling Next-Gen LLM Applications". https://microsoft.com/en-us/research/project/autogen/
3. **CrewAI Documentation** (2024). "CrewAI: Multi-Agent Framework". https://docs.crewai.com/
4. **HuggingFace** (2024). "Smolagents: Lightweight AI Agents". https://huggingface.co/docs/smolagents
5. **Pydantic** (2024). "Pydantic AI: Type-safe Agent Framework". https://ai.pydantic.dev/
6. **Bright Data** (2025). "Los 12 principales marcos de agentes de IA en 2025". https://brightdata.es/blog/ai/best-ai-agent-frameworks
7. **Analytics Vidhya** (2024). "Top 7 Frameworks for Building AI Agents in 2025". https://www.analyticsvidhya.com/blog/2024/07/ai-agent-frameworks/

**√öltima actualizaci√≥n:** Noviembre 2024  
**Frameworks cubiertos:** LangChain 0.1+, AutoGen v0.4, CrewAI, LangGraph, Semantic Kernel, Smolagents, LlamaIndex, Pydantic AI, Google ADK
