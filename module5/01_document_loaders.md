# Parte 1: Document Loaders - La Puerta de Entrada al RAG

![Document Loaders](https://img.shields.io/badge/RAG_Pipeline-Document_Loaders-4A90E2?style=for-the-badge)

## üìñ √çndice
1. [Fundamentos Conceptuales](#fundamentos-conceptuales)
2. [Tipos de Documentos y Desaf√≠os](#tipos-de-documentos-y-desaf√≠os)
3. [Document Loaders en LangChain](#document-loaders-en-langchain)
4. [Implementaci√≥n Paso a Paso](#implementaci√≥n-paso-a-paso)
5. [Mejores Pr√°cticas](#mejores-pr√°cticas)

---

## üéØ Fundamentos Conceptuales

### ¬øQu√© es un Document Loader?

Un **Document Loader** es el primer componente cr√≠tico en cualquier pipeline RAG. Su responsabilidad es transformar datos en bruto (PDFs, p√°ginas web, bases de datos, etc.) en un formato estructurado que el sistema pueda procesar.

```mermaid
graph LR
    A[Fuentes de Datos] --> B[Document Loader]
    B --> C[Documentos Estructurados]
    C --> D[Text Splitter]
    D --> E[Embeddings]
    E --> F[Vector Store]
    
    style B fill:#4A90E2,stroke:#2E5C8A,stroke-width:3px,color:#fff
```

### ¬øPor Qu√© Son Importantes?

Los Document Loaders no solo leen archivos, sino que:

1. **Preservan Metadata**: Informaci√≥n crucial como fuente, fecha, autor, p√°gina
2. **Normalizan Formatos**: Convierten diferentes formatos a una estructura com√∫n
3. **Manejan Errores**: Procesan archivos corruptos o mal formateados
4. **Optimizan Performance**: Cargan datos de manera eficiente (lazy loading, streaming)

> [!IMPORTANT]
> **La calidad de tu RAG nunca ser√° mejor que la calidad de tu ingesta de datos**. Un Document Loader mal configurado puede:
> - Perder informaci√≥n cr√≠tica (tablas, im√°genes, formato)
> - Introducir ruido (headers, footers, elementos de navegaci√≥n)
> - Fallar silenciosamente (errores no manejados)

---

## üìö Tipos de Documentos y Desaf√≠os

### Clasificaci√≥n de Documentos

| Tipo | Ejemplos | Desaf√≠os Principales |
|------|----------|---------------------|
| **Texto Plano** | `.txt`, `.md`, `.csv` | Encoding, delimitadores |
| **Documentos Estructurados** | `.pdf`, `.docx`, `.pptx` | Extracci√≥n de layout, tablas, im√°genes |
| **Web** | HTML, APIs | JavaScript din√°mico, rate limiting |
| **Bases de Datos** | SQL, NoSQL | Esquemas complejos, relaciones |
| **C√≥digo** | `.py`, `.js`, `.java` | Sintaxis, dependencias |
| **Multimedia** | Im√°genes, Audio, Video | Transcripci√≥n, OCR, multimodalidad |

### Desaf√≠os Comunes

#### 1. **Documentos No Estructurados**
```python
# ‚ùå Problema: PDF con layout complejo
# Texto extra√≠do: "Columna1Texto Columna2Texto TablaHeader"
# Resultado: Contexto mezclado e in√∫til
```

#### 2. **Metadata Faltante**
```python
# ‚ùå Sin metadata
doc = Document(page_content="Python es un lenguaje...")

# ‚úÖ Con metadata rica
doc = Document(
    page_content="Python es un lenguaje...",
    metadata={
        "source": "python_guide.pdf",
        "page": 5,
        "author": "Guido van Rossum",
        "date": "2024-01-15",
        "section": "Introducci√≥n",
        "language": "es"
    }
)
```

#### 3. **Encoding y Caracteres Especiales**
```python
# ‚ùå Error com√∫n
with open("documento.txt") as f:  # Asume UTF-8
    text = f.read()  # UnicodeDecodeError con Latin-1

# ‚úÖ Manejo robusto
import chardet

with open("documento.txt", "rb") as f:
    raw_data = f.read()
    encoding = chardet.detect(raw_data)["encoding"]
    text = raw_data.decode(encoding)
```

---

## üîß Document Loaders en LangChain

### Arquitectura de Document Loaders

LangChain proporciona una interfaz unificada para cargar documentos:

```python
from langchain.schema import Document

# Estructura base de un Document
class Document:
    page_content: str      # El texto del documento
    metadata: dict         # Informaci√≥n adicional
```

### Loaders Principales

#### 1. **TextLoader** - Archivos de Texto Plano

```python
from langchain_community.document_loaders import TextLoader

# Uso b√°sico
loader = TextLoader("documento.txt", encoding="utf-8")
documents = loader.load()

print(f"Documentos cargados: {len(documents)}")
print(f"Contenido: {documents[0].page_content[:100]}...")
print(f"Metadata: {documents[0].metadata}")
```

**Cu√°ndo usar**: Archivos `.txt`, `.md`, `.log`, c√≥digo fuente

#### 2. **PyPDFLoader** - Documentos PDF

```python
from langchain_community.document_loaders import PyPDFLoader

# Carga PDF con metadata por p√°gina
loader = PyPDFLoader("manual_tecnico.pdf")
pages = loader.load()

# Cada p√°gina es un Document separado
for i, page in enumerate(pages):
    print(f"P√°gina {i+1}:")
    print(f"  Contenido: {page.page_content[:100]}...")
    print(f"  Metadata: {page.metadata}")
```

**Caracter√≠sticas**:
- ‚úÖ Extrae texto p√°gina por p√°gina
- ‚úÖ Preserva n√∫mero de p√°gina en metadata
- ‚ùå No extrae im√°genes ni tablas complejas

#### 3. **UnstructuredPDFLoader** - PDFs Complejos

```python
from langchain_community.document_loaders import UnstructuredPDFLoader

# Para PDFs con layout complejo, tablas, im√°genes
loader = UnstructuredPDFLoader(
    "informe_complejo.pdf",
    mode="elements"  # "single" | "elements"
)
documents = loader.load()

# mode="elements" separa por tipo de elemento
for doc in documents:
    element_type = doc.metadata.get("category", "unknown")
    print(f"Tipo: {element_type}")
    print(f"Contenido: {doc.page_content[:100]}...")
```

**Ventajas**:
- ‚úÖ Detecta tablas, t√≠tulos, listas
- ‚úÖ Preserva estructura del documento
- ‚ö†Ô∏è Requiere dependencias adicionales (`unstructured`, `pdf2image`)

#### 4. **WebBaseLoader** - P√°ginas Web

```python
from langchain_community.document_loaders import WebBaseLoader

# Cargar contenido de una URL
loader = WebBaseLoader("https://python.langchain.com/docs/")
documents = loader.load()

print(f"T√≠tulo: {documents[0].metadata.get('title')}")
print(f"URL: {documents[0].metadata.get('source')}")
print(f"Contenido: {documents[0].page_content[:200]}...")
```

**Caracter√≠sticas**:
- ‚úÖ Extrae texto limpio (sin HTML)
- ‚úÖ Maneja JavaScript b√°sico
- ‚ùå No ejecuta JavaScript complejo (usar Playwright para eso)

#### 5. **DirectoryLoader** - M√∫ltiples Archivos

```python
from langchain_community.document_loaders import DirectoryLoader, TextLoader

# Cargar todos los archivos .md de un directorio
loader = DirectoryLoader(
    "docs/",
    glob="**/*.md",           # Patr√≥n de archivos
    loader_cls=TextLoader,    # Loader a usar
    show_progress=True,       # Barra de progreso
    use_multithreading=True   # Procesamiento paralelo
)

documents = loader.load()
print(f"Total documentos: {len(documents)}")
```

**Uso profesional**: Ingestar repositorios de documentaci√≥n completos

#### 6. **CSVLoader** - Datos Tabulares

```python
from langchain_community.document_loaders.csv_loader import CSVLoader

# Cada fila se convierte en un Document
loader = CSVLoader(
    file_path="productos.csv",
    csv_args={
        "delimiter": ",",
        "quotechar": '"',
        "fieldnames": ["id", "nombre", "descripcion", "precio"]
    }
)

documents = loader.load()

# Metadata incluye n√∫mero de fila
for doc in documents[:3]:
    print(f"Fila {doc.metadata['row']}: {doc.page_content}")
```

---

## üíª Implementaci√≥n Paso a Paso

### Ejemplo 1: Loader B√°sico con Manejo de Errores

```python
"""
Ejemplo B√°sico: Document Loader Robusto
Objetivo: Cargar documentos PDF con manejo de errores y metadata enriquecida
"""

from langchain_community.document_loaders import PyPDFLoader
from langchain.schema import Document
from pathlib import Path
from typing import List
import logging

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class RobustPDFLoader:
    """Loader de PDFs con manejo de errores y metadata enriquecida"""
    
    def __init__(self, file_path: str):
        self.file_path = Path(file_path)
        
    def load(self) -> List[Document]:
        """Carga el PDF con validaci√≥n y enriquecimiento de metadata"""
        
        # Validar que el archivo existe
        if not self.file_path.exists():
            raise FileNotFoundError(f"Archivo no encontrado: {self.file_path}")
        
        # Validar extensi√≥n
        if self.file_path.suffix.lower() != ".pdf":
            raise ValueError(f"Archivo no es PDF: {self.file_path}")
        
        try:
            # Cargar PDF
            loader = PyPDFLoader(str(self.file_path))
            documents = loader.load()
            
            # Enriquecer metadata
            for doc in documents:
                doc.metadata.update({
                    "filename": self.file_path.name,
                    "file_size_kb": self.file_path.stat().st_size / 1024,
                    "file_extension": self.file_path.suffix,
                    "total_pages": len(documents)
                })
            
            logger.info(f"‚úÖ Cargado: {self.file_path.name} ({len(documents)} p√°ginas)")
            return documents
            
        except Exception as e:
            logger.error(f"‚ùå Error cargando {self.file_path.name}: {str(e)}")
            raise


# Uso
if __name__ == "__main__":
    loader = RobustPDFLoader("manual_usuario.pdf")
    docs = loader.load()
    
    # Inspeccionar primer documento
    print(f"\nüìÑ Documento 1:")
    print(f"Contenido (primeros 200 chars): {docs[0].page_content[:200]}...")
    print(f"\nMetadata:")
    for key, value in docs[0].metadata.items():
        print(f"  {key}: {value}")
```

### Ejemplo 2: Loader Multi-Formato con Factory Pattern

```python
"""
Ejemplo Intermedio: Loader Multi-Formato
Objetivo: Sistema que detecta autom√°ticamente el tipo de archivo y usa el loader apropiado
"""

from langchain_community.document_loaders import (
    PyPDFLoader,
    TextLoader,
    CSVLoader,
    UnstructuredWordDocumentLoader
)
from langchain.schema import Document
from pathlib import Path
from typing import List, Type
from abc import ABC, abstractmethod


class DocumentLoaderFactory:
    """Factory para crear loaders seg√∫n el tipo de archivo"""
    
    # Mapeo de extensiones a loaders
    LOADER_MAP = {
        ".pdf": PyPDFLoader,
        ".txt": TextLoader,
        ".md": TextLoader,
        ".csv": CSVLoader,
        ".docx": UnstructuredWordDocumentLoader,
    }
    
    @classmethod
    def create_loader(cls, file_path: str):
        """Crea el loader apropiado seg√∫n la extensi√≥n del archivo"""
        path = Path(file_path)
        extension = path.suffix.lower()
        
        loader_class = cls.LOADER_MAP.get(extension)
        if not loader_class:
            raise ValueError(
                f"Tipo de archivo no soportado: {extension}\n"
                f"Soportados: {list(cls.LOADER_MAP.keys())}"
            )
        
        return loader_class(str(path))
    
    @classmethod
    def load_document(cls, file_path: str) -> List[Document]:
        """Carga un documento usando el loader apropiado"""
        loader = cls.create_loader(file_path)
        return loader.load()


class BatchDocumentLoader:
    """Carga m√∫ltiples documentos de diferentes formatos"""
    
    def __init__(self, file_paths: List[str]):
        self.file_paths = file_paths
        
    def load_all(self) -> List[Document]:
        """Carga todos los documentos"""
        all_documents = []
        
        for file_path in self.file_paths:
            try:
                docs = DocumentLoaderFactory.load_document(file_path)
                all_documents.extend(docs)
                print(f"‚úÖ Cargado: {Path(file_path).name} ({len(docs)} docs)")
            except Exception as e:
                print(f"‚ùå Error con {Path(file_path).name}: {str(e)}")
                continue
        
        return all_documents


# Uso
if __name__ == "__main__":
    # Lista de archivos de diferentes formatos
    files = [
        "documentos/manual.pdf",
        "documentos/readme.md",
        "documentos/datos.csv",
        "documentos/informe.docx"
    ]
    
    # Cargar todos
    batch_loader = BatchDocumentLoader(files)
    all_docs = batch_loader.load_all()
    
    print(f"\nüìä Total documentos cargados: {len(all_docs)}")
    
    # Agrupar por tipo
    by_type = {}
    for doc in all_docs:
        ext = doc.metadata.get("source", "").split(".")[-1]
        by_type[ext] = by_type.get(ext, 0) + 1
    
    print("\nüìà Distribuci√≥n por tipo:")
    for ext, count in by_type.items():
        print(f"  .{ext}: {count} documentos")
```

### Ejemplo 3: Loader Personalizado para Formato Propietario

```python
"""
Ejemplo Avanzado: Custom Document Loader
Objetivo: Crear un loader personalizado para un formato JSON espec√≠fico
"""

from langchain.document_loaders.base import BaseLoader
from langchain.schema import Document
from typing import List, Iterator
import json
from pathlib import Path


class CustomJSONLoader(BaseLoader):
    """
    Loader personalizado para archivos JSON con estructura espec√≠fica.
    
    Formato esperado:
    {
        "articles": [
            {
                "id": "123",
                "title": "T√≠tulo",
                "content": "Contenido...",
                "author": "Autor",
                "date": "2024-01-15",
                "tags": ["tag1", "tag2"]
            }
        ]
    }
    """
    
    def __init__(
        self,
        file_path: str,
        content_key: str = "content",
        metadata_keys: List[str] = None
    ):
        self.file_path = Path(file_path)
        self.content_key = content_key
        self.metadata_keys = metadata_keys or ["title", "author", "date", "tags"]
        
    def load(self) -> List[Document]:
        """Carga todos los documentos"""
        return list(self.lazy_load())
    
    def lazy_load(self) -> Iterator[Document]:
        """
        Carga lazy (generador) para archivos grandes.
        Ventaja: No carga todo en memoria de una vez.
        """
        with open(self.file_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        # Validar estructura
        if "articles" not in data:
            raise ValueError("JSON debe contener clave 'articles'")
        
        # Procesar cada art√≠culo
        for article in data["articles"]:
            # Extraer contenido
            content = article.get(self.content_key, "")
            
            if not content:
                continue  # Skip art√≠culos sin contenido
            
            # Construir metadata
            metadata = {
                "source": str(self.file_path),
                "format": "custom_json"
            }
            
            for key in self.metadata_keys:
                if key in article:
                    metadata[key] = article[key]
            
            # Crear documento
            yield Document(
                page_content=content,
                metadata=metadata
            )


class EnhancedJSONLoader(CustomJSONLoader):
    """Versi√≥n mejorada con validaci√≥n y transformaci√≥n"""
    
    def __init__(
        self,
        file_path: str,
        content_key: str = "content",
        metadata_keys: List[str] = None,
        min_content_length: int = 50,
        transform_content: bool = True
    ):
        super().__init__(file_path, content_key, metadata_keys)
        self.min_content_length = min_content_length
        self.transform_content = transform_content
    
    def _clean_content(self, content: str) -> str:
        """Limpia y normaliza el contenido"""
        # Eliminar espacios m√∫ltiples
        content = " ".join(content.split())
        
        # Eliminar caracteres de control
        content = "".join(char for char in content if char.isprintable() or char in "\n\t")
        
        return content.strip()
    
    def lazy_load(self) -> Iterator[Document]:
        """Carga con validaci√≥n y transformaci√≥n"""
        for doc in super().lazy_load():
            # Validar longitud m√≠nima
            if len(doc.page_content) < self.min_content_length:
                continue
            
            # Transformar contenido si est√° habilitado
            if self.transform_content:
                doc.page_content = self._clean_content(doc.page_content)
            
            # A√±adir metadata adicional
            doc.metadata["content_length"] = len(doc.page_content)
            doc.metadata["word_count"] = len(doc.page_content.split())
            
            yield doc


# Uso
if __name__ == "__main__":
    # Crear archivo JSON de ejemplo
    sample_data = {
        "articles": [
            {
                "id": "1",
                "title": "Introducci√≥n a RAG",
                "content": "RAG (Retrieval-Augmented Generation) es una t√©cnica que combina recuperaci√≥n de informaci√≥n con generaci√≥n de lenguaje natural...",
                "author": "Juan P√©rez",
                "date": "2024-01-15",
                "tags": ["RAG", "NLP", "AI"]
            },
            {
                "id": "2",
                "title": "Document Loaders",
                "content": "Los document loaders son componentes esenciales en cualquier pipeline RAG...",
                "author": "Mar√≠a Garc√≠a",
                "date": "2024-01-20",
                "tags": ["RAG", "LangChain"]
            }
        ]
    }
    
    # Guardar archivo de ejemplo
    with open("articles.json", "w", encoding="utf-8") as f:
        json.dump(sample_data, f, indent=2, ensure_ascii=False)
    
    # Cargar con loader personalizado
    loader = EnhancedJSONLoader(
        "articles.json",
        min_content_length=50,
        transform_content=True
    )
    
    documents = loader.load()
    
    print(f"üìö Documentos cargados: {len(documents)}\n")
    
    for i, doc in enumerate(documents, 1):
        print(f"Documento {i}:")
        print(f"  T√≠tulo: {doc.metadata.get('title')}")
        print(f"  Autor: {doc.metadata.get('author')}")
        print(f"  Palabras: {doc.metadata.get('word_count')}")
        print(f"  Tags: {doc.metadata.get('tags')}")
        print(f"  Contenido: {doc.page_content[:100]}...\n")
```

---

## ‚úÖ Mejores Pr√°cticas

### 1. **Siempre Enriquecer Metadata**

```python
# ‚ùå Metadata m√≠nima
doc = Document(page_content=text)

# ‚úÖ Metadata rica
doc = Document(
    page_content=text,
    metadata={
        "source": "documento.pdf",
        "page": 5,
        "section": "Cap√≠tulo 3",
        "author": "Juan P√©rez",
        "date": "2024-01-15",
        "language": "es",
        "doc_type": "technical_manual",
        "version": "2.0"
    }
)
```

**Por qu√©**: La metadata permite filtrado preciso durante retrieval.

### 2. **Manejo Robusto de Errores**

```python
def load_documents_safely(file_paths: List[str]) -> List[Document]:
    """Carga documentos con manejo de errores"""
    documents = []
    errors = []
    
    for path in file_paths:
        try:
            loader = DocumentLoaderFactory.create_loader(path)
            docs = loader.load()
            documents.extend(docs)
        except Exception as e:
            errors.append({"file": path, "error": str(e)})
            logger.error(f"Error cargando {path}: {e}")
    
    # Reportar errores al final
    if errors:
        logger.warning(f"‚ö†Ô∏è {len(errors)} archivos fallaron")
        for error in errors:
            logger.warning(f"  - {error['file']}: {error['error']}")
    
    return documents
```

### 3. **Lazy Loading para Archivos Grandes**

```python
# ‚ùå Carga todo en memoria
documents = loader.load()  # Puede causar OOM con archivos grandes

# ‚úÖ Lazy loading (generador)
for document in loader.lazy_load():
    process_document(document)  # Procesa uno a la vez
```

### 4. **Validaci√≥n de Contenido**

```python
def validate_document(doc: Document) -> bool:
    """Valida que un documento sea √∫til"""
    
    # Contenido m√≠nimo
    if len(doc.page_content) < 50:
        return False
    
    # No solo espacios en blanco
    if not doc.page_content.strip():
        return False
    
    # Metadata esencial presente
    required_metadata = ["source"]
    if not all(key in doc.metadata for key in required_metadata):
        return False
    
    return True

# Filtrar documentos inv√°lidos
valid_docs = [doc for doc in documents if validate_document(doc)]
```

### 5. **Logging y Observabilidad**

```python
import logging
from datetime import datetime

logger = logging.getLogger(__name__)

def load_with_logging(file_path: str) -> List[Document]:
    """Carga documentos con logging detallado"""
    start_time = datetime.now()
    
    logger.info(f"üîÑ Iniciando carga: {file_path}")
    
    try:
        loader = DocumentLoaderFactory.create_loader(file_path)
        documents = loader.load()
        
        duration = (datetime.now() - start_time).total_seconds()
        
        logger.info(
            f"‚úÖ Carga exitosa: {file_path}\n"
            f"   Documentos: {len(documents)}\n"
            f"   Duraci√≥n: {duration:.2f}s"
        )
        
        return documents
        
    except Exception as e:
        logger.error(f"‚ùå Error cargando {file_path}: {str(e)}")
        raise
```

---

## üéØ Resumen y Pr√≥ximos Pasos

### Lo que Aprendimos

‚úÖ **Document Loaders** son el primer paso cr√≠tico en RAG  
‚úÖ **Metadata rica** mejora significativamente la calidad del retrieval  
‚úÖ **Manejo de errores** es esencial para sistemas en producci√≥n  
‚úÖ **Diferentes formatos** requieren diferentes loaders  
‚úÖ **Lazy loading** optimiza memoria para archivos grandes  

### Checklist de Implementaci√≥n

- [ ] Identificar todos los formatos de documentos en tu sistema
- [ ] Seleccionar loaders apropiados para cada formato
- [ ] Implementar enriquecimiento de metadata
- [ ] A√±adir manejo robusto de errores
- [ ] Configurar logging y monitoreo
- [ ] Validar calidad de documentos cargados

### Pr√≥ximo Paso

Una vez que tus documentos est√°n cargados, el siguiente paso es **dividirlos en chunks** para optimizar el retrieval.

‚û°Ô∏è **[Continuar a Parte 2: Text Splitters](02_text_splitters.md)**

---

<div align="center">

**[‚¨ÖÔ∏è Volver al M√≥dulo 5](README.md)** | **[Siguiente: Text Splitters ‚û°Ô∏è](02_text_splitters.md)**

</div>
