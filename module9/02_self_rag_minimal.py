"""
02_self_rag_minimal.py
======================
Implementaci√≥n minimalista de la l√≥gica Self-RAG (Self-Reflective RAG).
El agente genera una respuesta y luego se auto-critica para verificar
si alucin√≥ o si la respuesta es relevante.

M√©tricas simuladas:
- IsRel (Relevance): ¬øEs relevante el contexto?
- IsSup (Supported): ¬øLa respuesta est√° soportada por el contexto?

Requisitos:
pip install langchain langchain-openai
"""

from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser

llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

# 1. Componentes

def retrieve(query: str):
    """Simula un retriever"""
    # En prod, esto ser√≠a una b√∫squeda vectorial real
    knowledge_base = {
        "capital de francia": "La capital de Francia es Par√≠s.",
        "capital de marte": "Marte no tiene capital conocida por humanos."
    }
    return knowledge_base.get(query.lower(), "No tengo informaci√≥n sobre eso.")

def generate(query: str, context: str):
    """Generador est√°ndar"""
    prompt = ChatPromptTemplate.from_template(
        "Contexto: {context}\nPregunta: {query}\nRespuesta:"
    )
    chain = prompt | llm | StrOutputParser()
    return chain.invoke({"query": query, "context": context})

def grade_relevance(query: str, context: str):
    """Cr√≠tico: Eval√∫a relevancia del contexto"""
    prompt = ChatPromptTemplate.from_template(
        "Pregunta: {query}\nContexto: {context}\n"
        "¬øEl contexto contiene informaci√≥n relevante para responder? Responde SOLO 'YES' o 'NO'."
    )
    chain = prompt | llm | StrOutputParser()
    return chain.invoke({"query": query, "context": context}).strip()

def grade_groundedness(answer: str, context: str):
    """Cr√≠tico: Eval√∫a si la respuesta est√° soportada (No alucinaci√≥n)"""
    prompt = ChatPromptTemplate.from_template(
        "Contexto: {context}\nRespuesta: {answer}\n"
        "¬øLa respuesta est√° totalmente soportada por el contexto? Responde SOLO 'YES' o 'NO'."
    )
    chain = prompt | llm | StrOutputParser()
    return chain.invoke({"answer": answer, "context": context}).strip()

# 2. Pipeline Self-RAG

def self_rag_pipeline(query: str):
    print(f"üîç Pregunta: {query}")
    
    # Paso 1: Retrieve
    context = retrieve(query)
    print(f"üìÑ Contexto recuperado: {context}")
    
    # Paso 2: Critique Retrieval (IsRel)
    relevance = grade_relevance(query, context)
    print(f"ü§î IsRel (Relevante): {relevance}")
    
    if relevance == "NO":
        return "‚ùå No pude encontrar informaci√≥n relevante para responder con seguridad."
    
    # Paso 3: Generate
    answer = generate(query, context)
    print(f"ü§ñ Respuesta generada: {answer}")
    
    # Paso 4: Critique Generation (IsSup)
    grounded = grade_groundedness(answer, context)
    print(f"üõ°Ô∏è IsSup (Soportada): {grounded}")
    
    if grounded == "NO":
        # Aqu√≠ podr√≠amos intentar regenerar o buscar de nuevo
        return "‚ö†Ô∏è La respuesta generada podr√≠a contener alucinaciones. Se ha bloqueado."
    
    return f"‚úÖ Respuesta Final: {answer}"

def main():
    print("--- Test 1: Pregunta Conocida ---")
    print(self_rag_pipeline("Capital de Francia"))
    
    print("\n--- Test 2: Pregunta Desconocida (Simulando fallo de contexto) ---")
    # Simulamos que el retriever fall√≥ o trajo basura
    print(self_rag_pipeline("Capital de Atlantis"))

if __name__ == "__main__":
    main()
