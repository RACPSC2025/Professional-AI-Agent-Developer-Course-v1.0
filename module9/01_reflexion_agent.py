"""
01_reflexion_agent.py
=====================
Implementaci√≥n de un Agente de Reflexi√≥n (Reflexion) usando LangGraph.

Este agente intenta resolver una tarea de programaci√≥n. Si falla (error de sintaxis o ejecuci√≥n),
entra en un bucle de "Reflexi√≥n" donde analiza el error y propone una soluci√≥n antes de reintentar.

Ciclo:
1.  **Draft:** Escribir c√≥digo.
2.  **Execute:** Correr c√≥digo.
3.  **Reflect:** Si falla -> Analizar traceback -> Guardar lecci√≥n en memoria.
4.  **Retry:** Escribir nuevo c√≥digo considerando la lecci√≥n.

Requisitos:
pip install langgraph langchain langchain_openai
"""

from typing import List, TypedDict
from langchain_openai import ChatOpenAI
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langgraph.graph import StateGraph, END

# --- 1. Definici√≥n del Estado (Memoria del Grafo) ---
class AgentState(TypedDict):
    messages: List[BaseMessage]
    code_solution: str
    error_log: str
    reflection: str
    iterations: int

# --- 2. Nodos del Grafo (Pasos del Pensamiento) ---

llm = ChatOpenAI(model="gpt-4", temperature=0)

def generate_code(state: AgentState):
    """Nodo Generador: Escribe la soluci√≥n inicial o corregida."""
    print(f"‚úçÔ∏è Generando c√≥digo (Iteraci√≥n {state['iterations']})...")
    
    messages = state['messages']
    # Si hay reflexi√≥n previa, la inyectamos en el contexto
    if state.get('reflection'):
        messages.append(HumanMessage(content=f"Feedback anterior: {state['reflection']}. Por favor corrige el c√≥digo."))
    
    # Simulamos la generaci√≥n (en prod, usar√≠as un prompt real de codificaci√≥n)
    # Aqu√≠ hardcodeamos un error intencional en la primera vuelta para demo
    if state['iterations'] == 0:
        code = "print('Hola Mundo' + 5)" # Error de tipos
    else:
        code = "print('Hola Mundo' + ' 5')" # Corregido
        
    return {"code_solution": code, "iterations": state['iterations'] + 1}

def execute_code(state: AgentState):
    """Nodo Ejecutor: Corre el c√≥digo y captura errores."""
    print("‚öôÔ∏è Ejecutando c√≥digo...")
    code = state['code_solution']
    try:
        exec(code)
        print("‚úÖ Ejecuci√≥n exitosa.")
        return {"error_log": ""}
    except Exception as e:
        print(f"‚ùå Error detectado: {e}")
        return {"error_log": str(e)}

def reflect_on_error(state: AgentState):
    """Nodo Reflexivo: Analiza por qu√© fall√≥."""
    print("üß† Reflexionando sobre el error...")
    error = state['error_log']
    code = state['code_solution']
    
    # El LLM analiza el error
    prompt = f"El c√≥digo `{code}` fall√≥ con el error `{error}`. Explica brevemente por qu√© y c√≥mo arreglarlo."
    reflection = llm.invoke(prompt).content
    
    print(f"üí° Insight: {reflection}")
    return {"reflection": reflection}

# --- 3. Construcci√≥n del Grafo (Wiring) ---

workflow = StateGraph(AgentState)

# A√±adir Nodos
workflow.add_node("generate", generate_code)
workflow.add_node("execute", execute_code)
workflow.add_node("reflect", reflect_on_error)

# Definir Flujo
workflow.set_entry_point("generate")
workflow.add_edge("generate", "execute")

# Edge Condicional: ¬øHubo error?
def check_execution(state: AgentState):
    if state['error_log']:
        return "reflect" # Si hay error, ir a reflexionar
    return END           # Si no, terminar

workflow.add_conditional_edges(
    "execute",
    check_execution,
    {
        "reflect": "reflect",
        END: END
    }
)

workflow.add_edge("reflect", "generate") # Despu√©s de reflexionar, intentar de nuevo

# Compilar
app = workflow.compile()

# --- 4. Ejecuci√≥n ---

if __name__ == "__main__":
    print("üöÄ Iniciando Agente de Reflexi√≥n...")
    
    initial_state = {
        "messages": [HumanMessage(content="Escribe un script que sume texto y n√∫meros.")],
        "iterations": 0,
        "code_solution": "",
        "error_log": "",
        "reflection": ""
    }
    
    # Ejecutar el grafo
    for event in app.stream(initial_state):
        pass # Los prints ya est√°n en los nodos
