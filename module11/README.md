# MÃ³dulo 11: LLMOps & Agent Observability

![Module 11 Banner](../images/module11_banner.png)

> "En 2025, no monitoreamos modelos. Monitoreamos la *trayectoria* del pensamiento de los agentes."

## ğŸ¯ Objetivos del MÃ³dulo

Lanzar un agente es fÃ¡cil. Mantenerlo cuerdo en producciÃ³n es difÃ­cil. En este mÃ³dulo, aprenderÃ¡s **LLMOps** moderno:

**Lo que vas a dominar:**
1.  ğŸ•µï¸ **Agent Observability:** Tracing profundo con **LangSmith**.
2.  âš–ï¸ **Ethical Guardrails:** DetecciÃ³n de sesgos en tiempo real con **Arize Phoenix**.
3.  ğŸ“‰ **Trajectory Evaluation:** Â¿El agente tomÃ³ el camino Ã³ptimo o dio vueltas innecesarias?

---

## ğŸ“š Conceptos Clave (Nov 2025)

### 1. De "Model Monitoring" a "Agent Observability"
En 2024 monitoreÃ¡bamos latencia y tokens. En 2025, monitoreamos **IntenciÃ³n y EjecuciÃ³n**.
- **Tracing:** Ver cada paso (Thought -> Action -> Observation).
- **Cost Attribution:** Â¿QuÃ© paso del agente gastÃ³ $0.50 innecesariamente?

### 2. Trajectory Evaluation
No basta con que la respuesta sea correcta.
- **Ejemplo:** Si pides "Hora en Londres", y el agente busca en Google "Historia de Londres" -> "Clima Londres" -> "Hora Londres".
- **Resultado:** Correcto.
- **Trayectoria:** Ineficiente (Fallo de razonamiento).

---

## ğŸŒ High Impact Social/Professional Example (Nov 2025)

> **Proyecto: "FairHire" - Monitor de Sesgos en Tiempo Real**
>
> Este ejemplo implementa un sistema de **Observabilidad Ã‰tica** para un agente de Recursos Humanos, bloqueando respuestas sesgadas antes de que lleguen al usuario.

### El Problema
Los agentes de HR pueden heredar sesgos sutiles (gÃ©nero, edad) de sus datos de entrenamiento, exponiendo a la empresa a demandas.

### La SoluciÃ³n
Un "Guardrail Agent" que intercepta cada respuesta, la analiza con **Arize Phoenix** en busca de sesgos, y si detecta >0.7 de probabilidad, reescribe la respuesta.

```python
"""
Project: FairHire
Stack: LangChain, Arize Phoenix, OpenAI
"""
from phoenix.evals import HallucinationEvaluator, QAEvaluator
from phoenix.session.evaluation import get_qa_with_reference
from langsmith import trace

# 1. El Agente de HR (Propenso a errores)
@trace
def hr_agent(resume_text):
    # SimulaciÃ³n de lÃ³gica interna
    return call_llm(f"EvalÃºa este CV: {resume_text}")

# 2. El Monitor de Sesgos (Guardrail)
@trace
def bias_guardrail(response_text):
    print("ğŸ›¡ï¸ Scanning for bias...")
    
    # Usamos un LLM-Judge especializado en Ã©tica
    evaluation = call_llm_judge(
        prompt=f"Analiza si este texto tiene sesgo de gÃ©nero o edad: '{response_text}'. Responde JSON.",
        model="gpt-5.1-audit"
    )
    
    if evaluation['bias_score'] > 0.7:
        print(f"ğŸš¨ BIAS DETECTED: {evaluation['reason']}")
        return rewrite_neutral(response_text)
    
    return response_text

# 3. Pipeline Seguro
def secure_hiring_flow(resume):
    raw_response = hr_agent(resume)
    safe_response = bias_guardrail(raw_response)
    return safe_response
```

**Impacto Social:**
- **Justicia AlgorÃ­tmica:** Garantiza que la IA no perpetÃºe discriminaciÃ³n histÃ³rica.
- **Confianza Corporativa:** Permite a las empresas desplegar agentes en Ã¡reas sensibles con seguridad.

---

## ğŸ› ï¸ Proyectos PrÃ¡cticos

### ğŸ•µï¸ Proyecto 1: LangSmith Tracing
Instrumentar un agente complejo y visualizar su "Ã¡rbol de pensamiento" en la nube para detectar bucles infinitos.

### ğŸ  Proyecto 2: Local Observability (Phoenix)
Levantar un servidor local de Phoenix para monitorear un agente sin enviar datos sensibles a la nube (ideal Banca/Salud).

### âš–ï¸ Proyecto 3: FairHire (ImplementaciÃ³n)
El sistema de monitoreo de sesgos descrito arriba, con un dataset de CVs de prueba.

---

## ğŸ“Š El Stack Ganador 2025 (LLMOps)

| Herramienta | Uso Principal | Tipo |
| :--- | :--- | :--- |
| **LangSmith** | Tracing & Debugging | SaaS (Cloud) |
| **Arize Phoenix** | Evals & Bias Detection | Open Source (Local) |
| **OpenTelemetry** | EstÃ¡ndar de Datos | Protocolo |
| **Ragas** | MÃ©tricas RAG (PrecisiÃ³n) | LibrerÃ­a |

---

## ğŸš€ PrÃ³ximos Pasos

â¡ï¸ **[MÃ³dulo 12: Protocolos de Agentes](../module12/README.md)**

<div align="center">

**[â¬…ï¸ MÃ³dulo Anterior](../module10/README.md)** | **[ğŸ  Inicio](../README.md)**

</div>

---

**Ãšltima actualizaciÃ³n:** Noviembre 2025
**Stack:** LangSmith, Arize Phoenix
**Conceptos:** Agent Observability, Ethical Guardrails
