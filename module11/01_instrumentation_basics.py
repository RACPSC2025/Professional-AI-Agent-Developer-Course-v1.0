"""
01_instrumentation_basics.py
============================
Instrumentaci√≥n B√°sica con LangSmith.

Este script demuestra c√≥mo "encender la luz" en tu agente.
Al ejecutarlo, cada paso (llamada a LLM, uso de herramienta) se enviar√° a LangSmith.

Requisitos:
1. Crear cuenta en https://smith.langchain.com/
2. Obtener API Key.
3. pip install langchain langchain-openai langsmith

Variables de Entorno Requeridas:
- LANGCHAIN_TRACING_V2=true
- LANGCHAIN_ENDPOINT="https://api.smith.langchain.com"
- LANGCHAIN_API_KEY="<tu-api-key>"
- LANGCHAIN_PROJECT="curso-agentes-module11"
"""

import os
import time
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain.callbacks.tracers import LangChainTracer

# Configuraci√≥n (Idealmente cargar desde .env)
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_PROJECT"] = "Module 11 Demo"
# os.environ["LANGCHAIN_API_KEY"] = "sk-..." # Aseg√∫rate de tener esto setead

def build_agent():
    """Construye una cadena simple para demostraci√≥n."""
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", "Eres un experto en observabilidad de software. S√© t√©cnico pero claro."),
        ("user", "{question}")
    ])
    
    # Chain simple: Prompt -> LLM -> String
    chain = prompt | llm | StrOutputParser()
    return chain

if __name__ == "__main__":
    print("üïµÔ∏è  Iniciando Trace Demo con LangSmith...")
    
    if not os.environ.get("LANGCHAIN_API_KEY"):
        print("‚ö†Ô∏è  ADVERTENCIA: No se detect√≥ LANGCHAIN_API_KEY. El tracing fallar√° o no se ver√°.")
    
    agent = build_agent()
    
    questions = [
        "¬øPor qu√© es importante el distributed tracing en microservicios?",
        "Explica la diferencia entre m√©tricas y logs."
    ]
    
    for q in questions:
        print(f"\n‚ùì Preguntando: {q}")
        start = time.time()
        
        # Al invocar la cadena, LangChain env√≠a autom√°ticamente los datos a LangSmith
        # gracias a las variables de entorno.
        response = agent.invoke({"question": q})
        
        end = time.time()
        print(f"‚úÖ Respuesta ({end-start:.2f}s): {response[:100]}...")
    
    print("\n‚ú® Ve a https://smith.langchain.com/ para ver tus trazas en tiempo real.")
