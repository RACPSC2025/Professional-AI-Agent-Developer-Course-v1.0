"""
03_agent_evaluation_pipeline.py
===============================
Pipeline de EvaluaciÃ³n AutomÃ¡tica con Ragas.

Este script simula un proceso de CI/CD (IntegraciÃ³n Continua) para tu Agente.
EvalÃºa la calidad de las respuestas usando mÃ©tricas objetivas.

MÃ©tricas usadas:
1.  **Faithfulness:** Â¿La respuesta es fiel al contexto recuperado?
2.  **Answer Relevance:** Â¿La respuesta contesta la pregunta del usuario?

Requisitos:
pip install ragas datasets
"""

import os
from datasets import Dataset
from ragas import evaluate
from ragas.metrics import faithfulness, answer_relevancy
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

# ConfiguraciÃ³n
# os.environ["OPENAI_API_KEY"] = "sk-..."

# --- 1. Dataset de Prueba ("Golden Dataset") ---
# En producciÃ³n, esto vendrÃ­a de un CSV o JSON anotado por humanos.
data = {
    'question': [
        'Â¿QuiÃ©n ganÃ³ la copa del mundo 2022?',
        'Â¿CuÃ¡l es la capital de Francia?',
        'Explica la teorÃ­a de la relatividad en 5 palabras.'
    ],
    'answer': [
        'Argentina ganÃ³ la copa del mundo.', # Respuesta del Agente
        'ParÃ­s es la capital.',
        'EnergÃ­a igual a masa por velocidad.'
    ],
    'contexts': [
        ['Argentina derrotÃ³ a Francia en la final de Qatar 2022.'], # Contexto recuperado (RAG)
        ['ParÃ­s es la ciudad mÃ¡s poblada y capital de Francia.'],
        ['E=mc^2 es la fÃ³rmula famosa de Einstein.']
    ],
    'ground_truth': [
        'Argentina',
        'ParÃ­s',
        'E=mc^2 relaciona energÃ­a y masa.'
    ]
}

def run_evaluation():
    print("ğŸ§ª Iniciando EvaluaciÃ³n de Calidad del Agente...")
    
    # Convertir a formato HuggingFace Dataset
    dataset = Dataset.from_dict(data)
    
    # Ejecutar Ragas
    # Ragas usa un LLM (GPT-4/3.5) como "Juez" para calificar al Agente.
    results = evaluate(
        dataset=dataset,
        metrics=[
            faithfulness,
            answer_relevancy
        ],
        llm=ChatOpenAI(model="gpt-3.5-turbo"),
        embeddings=OpenAIEmbeddings()
    )
    
    print("\nğŸ“Š Reporte de Resultados:")
    print(results)
    
    # ValidaciÃ³n tipo CI/CD
    df = results.to_pandas()
    avg_faithfulness = df["faithfulness"].mean()
    
    print(f"\nPromedio Faithfulness: {avg_faithfulness:.2f}")
    
    if avg_faithfulness < 0.8:
        print("âŒ FALLO: La fidelidad del agente es baja. No desplegar a producciÃ³n.")
    else:
        print("âœ… Ã‰XITO: El agente cumple los estÃ¡ndares de calidad.")

if __name__ == "__main__":
    run_evaluation()
